{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dfffc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import scanpy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, DataLoader, Batch\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "from torch_geometric.nn import GATConv, GCNConv, SAGEConv, MessagePassing, Linear\n",
    "import random\n",
    "from scipy.io import mmread\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torcheval.metrics.functional import multiclass_f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "019e3865",
   "metadata": {},
   "outputs": [],
   "source": [
    "hicmatrix  =pd.read_csv(\"../../chrX_1000000_hic.txt\",header = None)\n",
    "# hicmatrix_test = pd.read_csv(\"../../chrX_2000000_hic.txt\",header = None)\n",
    "epigenomic = pd.read_csv(\"../../train_epigemnomic_1000000.csv\",header =  0).iloc[:,1:].to_numpy()\n",
    "label = pd.read_csv(\"../../train_label.csv\",header = 0).iloc[:,1:].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "114adefa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "       ...,\n",
       "       [  0.,   0.,   0., ..., 157., 269.,  24.],\n",
       "       [  0.,   0.,   0., ..., 269., 130., 233.],\n",
       "       [  0.,   0.,   0., ...,  24., 233., 134.]], dtype=float32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hicmatrix_train_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "563a3b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hicmatrix_train  =pd.read_csv(\"../../chrX_1000000_hic.txt\",header = None)\n",
    "# hicmatrix_test = pd.read_csv(\"../../chrX_2000000_hic.txt\",header = None)\n",
    "# epigenomic_test = pd.read_csv(\"../../test_epigemnomic_2000000.csv\",header =  0).iloc[:,1:].to_numpy()\n",
    "# label_test = pd.read_csv(\"../../test_label.csv\",header = 0).iloc[:,1:].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cefd4f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2001, 24)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epigenomic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19d6b641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([1950,   51]))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(label, return_counts=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6b74b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "hicmatrix_np =hicmatrix.to_numpy(dtype=np.float32)\n",
    "# hicmatrix_test_np = hicmatrix_test.to_numpy(dtype= np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b622da2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random_array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m label \u001b[38;5;241m=\u001b[39m random_array\n",
      "\u001b[0;31mNameError\u001b[0m: name 'random_array' is not defined"
     ]
    }
   ],
   "source": [
    "# label = random_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "806fce9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[3, 1], edge_index=[2, 4])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "edge_index = torch.tensor([[0, 1, 1, 2],\n",
    "                           [1, 0, 2, 1]], dtype=torch.long)\n",
    "x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91439005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of edges: 61946\n"
     ]
    }
   ],
   "source": [
    "# From Whitney\n",
    "\n",
    "def create_comp_graph(correlation, min_corr):\n",
    "    '''Get a graph based on highly correlated features (feat) and given correlation (corr).'''\n",
    "    s_l = [] # Gene 1 = Node 1\n",
    "    d_l  = [] # Gene 2 = Node 2\n",
    "    for i in range(0, correlation.shape[0]):\n",
    "        for j in range(0, correlation.shape[1]):# Get edge and correlation\n",
    "            if correlation[i][j] >= min_corr and i != j: # Ensure the features are at least given correlation (and it won't be a self correlated edge i. e. 1 --> 1)\n",
    "                s_l.append(i)\n",
    "                d_l.append(j)\n",
    "            else:\n",
    "                continue\n",
    "    print(f\"Number of edges: {len(s_l)}\") # Prints # of edges so you can make sure it isn't empty/too large\n",
    "    edge_index = np.array([s_l, d_l]) # Convert to array\n",
    "    return edge_index # Return edge index\n",
    "\n",
    "edge_index = create_comp_graph(hicmatrix_np, 10)\n",
    "temp_edge_index = edge_index\n",
    "# edge_index_test = create_comp_graph(hicmatrix_test_np,10)\n",
    "# temp_edge_index_test = edge_index_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db68bd2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  21,   22,   22,  ..., 2000, 2000, 2000],\n",
       "        [  22,   21,   23,  ..., 1997, 1998, 1999]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "240a01bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  21,   22,   22, ..., 2000, 2000, 2000],\n",
       "       [  22,   21,   23, ..., 1997, 1998, 1999]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0cc2121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 12) -> None:\n",
    "    '''This function allows us to set the seed for the notebook.'''\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    print(f\"Random seed set as {seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "226c02d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# Splitting into train and test sets\n",
    "\n",
    "# note that the training and testing matrices are the same length\n",
    "# indices = np.arange(len(epigenomic_train.index))\n",
    "# np.random.shuffle(indices)\n",
    "# training_exp_shuffled = training_head_expression.iloc[indices].to_numpy(dtype=np.float32)\n",
    "# training_age_labels = encoded_training_age.iloc[indices].to_numpy(dtype=np.int64)\n",
    "# np.random.shuffle(indices)\n",
    "# testing_exp_shuffled = testing_head_expression.iloc[indices].to_numpy(dtype=np.float32)\n",
    "# testing_age_labels = encoded_testing_age.iloc[indices].to_numpy(dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00c4dbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1\n",
    "# training_exp_shuffled = training_exp_shuffled + epsilon\n",
    "# training_exp_shuffled = np.log2(training_exp_shuffled)\n",
    "# testing_exp_shuffled = testing_exp_shuffled + epsilon\n",
    "# testing_exp_shuffled = np.log2(testing_exp_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82b307e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_81557/2785758134.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  edge_index = torch.tensor(edge_index, dtype = torch.int64)\n"
     ]
    }
   ],
   "source": [
    "# edge_index_train = torch.tensor(edge_index_train, dtype=torch.int64)\n",
    "# edge_index_test = torch.tensor(edge_index_test,dtype = torch.int64)\n",
    "# train_data = []\n",
    "# test_data = []\n",
    "edge_index = torch.tensor(edge_index, dtype = torch.int64)\n",
    "data = []\n",
    "# Function to convert graph data to PyTorch Geometric Data object\n",
    "def create_data_object(x, y, edge_index):\n",
    "    x = torch.tensor(x, dtype=torch.float32)\n",
    "    y = torch.tensor(y, dtype=torch.long)\n",
    "    return Data(x=x, y=y, edge_index=edge_index)\n",
    "\n",
    "# Create training dataset\n",
    "for j in range(2000):\n",
    "    x = epigenomic[j]\n",
    "    y = (label[j])\n",
    "    #y_train = training_age_labels[j]\n",
    "    data.append(create_data_object(x, y, edge_index))\n",
    "\n",
    "# # Create training dataset\n",
    "# for j in range(2000):\n",
    "#     x_train = epigenomic_train[j]\n",
    "#     y_train = n(label_train[j])\n",
    "#     #y_train = training_age_labels[j]\n",
    "#     train_data.append(create_data_object(x_train, y_train, edge_index_train))\n",
    "\n",
    "# # Create testing dataset\n",
    "# for k in range(2000):\n",
    "#     x_test = epigenomic_test[k]\n",
    "#     y_test = (label_test[k])\n",
    "#     #y_test = testing_age_labels[k]\n",
    "#     test_data.append(create_data_object(x_test, y_test, edge_index_test))\n",
    "\n",
    "# Convert lists of Data objects to Batch objects\n",
    "# train_data = Batch.from_data_list(train_data)\n",
    "# test_data = Batch.from_data_list(test_data)\n",
    "# data = create_data_object(training_exp_shuffled[2001], np.argmax(training_sex_labels[2001]), edge_index)\n",
    "# g = to_networkx(data, to_undirected=True)\n",
    "# nx.draw(g)\n",
    "\n",
    "\n",
    "\n",
    "# # Create DataLoader for training and testing\n",
    "# train_loader = DataLoader(train_data, batch_size=75, shuffle=True)\n",
    "# test_loader = DataLoader(test_data, batch_size=75, shuffle=False)\n",
    "\n",
    "# data_loader = DataLoader(train_data, batch_size=75, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a01ef16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/oscar/data/larschan/gcn_gps/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "data = DataLoader(data, batch_size = 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f24f825",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataLoader' object has no attribute 'num_edges'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data\u001b[38;5;241m.\u001b[39mnum_edges\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataLoader' object has no attribute 'num_edges'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8cd914d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/oscar/data/larschan/gcn_gps/lib/python3.8/site-packages/torch_geometric/graphgym/config.py:19: UserWarning: Could not define global config object. Please install 'yacs' via 'pip install yacs' in order to use GraphGym\n",
      "  warnings.warn(\"Could not define global config object. Please install \"\n",
      "/oscar/data/larschan/gcn_gps/lib/python3.8/site-packages/torch_geometric/graphgym/imports.py:14: UserWarning: Please install 'pytorch_lightning' via  'pip install pytorch_lightning' in order to use GraphGym\n",
      "  warnings.warn(\"Please install 'pytorch_lightning' via  \"\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import global_mean_pool, global_max_pool\n",
    "from torch_geometric.graphgym import init_weights\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim1, num_labels):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = SAGEConv(1, hidden_dim1)\n",
    "        self.init_weights(self.conv1)\n",
    "        # self.conv2 = SAGEConv(hidden_dim1, hidden_dim2)\n",
    "        # self.init_weights(self.conv2)\n",
    "        self.conv3 = SAGEConv(hidden_dim1, num_labels)\n",
    "        self.init_weights(self.conv3)\n",
    "        # self.conv4 = SAGEConv(hidden_dim3, num_labels)\n",
    "        # self.init_weights(self.conv4)\n",
    "        self.lin = Linear(num_labels, num_labels)\n",
    "    def forward(self, x, edge_index, batch=None):\n",
    "        print(edge_index)\n",
    "        x = F.leaky_relu(self.conv1(x, edge_index))\n",
    "       # x = F.leaky_relu(self.conv2(x, edge_index))\n",
    "        x = F.leaky_relu(self.conv3(x, edge_index))\n",
    "        # x = F.leaky_relu(self.conv4(x, edge_index))\n",
    "        x = global_mean_pool(x, batch) \n",
    "        x = self.lin(x)\n",
    "        x = F.log_softmax(x, dim=edge_index)\n",
    "        return x\n",
    "\n",
    "    def init_weights(self, layer):\n",
    "        if hasattr(layer, 'weight') and layer.weight is not None:\n",
    "            xavier_uniform_(layer.weight.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad77111f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): SAGEConv(1, 64, aggr=mean)\n",
      "  (conv3): SAGEConv(64, 4, aggr=mean)\n",
      "  (lin): Linear(4, 4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "import tqdm\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_labels=4\n",
    "\n",
    "model = GCN(64, num_labels).to(device)\n",
    "print(model)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion =  nn.CrossEntropyLoss() # change loss for binary classification vs multiclass\n",
    "\n",
    "def accuracy(predictions, targets):\n",
    "    # Assuming predictions and targets are tensors\n",
    "    _, predicted_classes = predictions.max(dim=1)\n",
    "    correct = (predicted_classes == targets).sum().item()\n",
    "    accuracy = correct / targets.size(0)\n",
    "    return accuracy\n",
    "\n",
    "def train(train_loader):\n",
    "    model.train()\n",
    "    avgLoss = 0\n",
    "    avgAcc = 0\n",
    "    for data in tqdm.tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        data.x = torch.reshape(data.x, (data.x.shape[0], 1)).to(torch.float32).to(device)\n",
    "        # data.x = data.x.view(-1, 1).to(torch.float32)\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        #target = torch.reshape(data.y, (100,2)) # CHANGE DIMENSIONS AS YOU CHANGE BATCH SIZE\n",
    "        loss = criterion(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        avgLoss += loss\n",
    "        avgAcc += accuracy(out, data.y)\n",
    "    return (avgLoss / len(train_loader)), (avgAcc / len(train_loader))\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in loader: \n",
    "            # data.x = data.x.view(-1, 1).to(torch.float32)\n",
    "        data.x = torch.reshape(data.x, (data.x.shape[0], 1)).to(torch.float32).to(device)\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        #target = torch.reshape(data.y, (100,2))\n",
    "        pred = torch.argmax(out, dim=1)\n",
    "        correct += int((pred == data.y).sum())\n",
    "    return correct / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9204ae51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/27 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  21,   22,   22,  ..., 3776, 3776, 3776],\n",
      "        [  22,   21,   23,  ..., 3773, 3774, 3775]])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Encountered an index error. Please ensure that all indices in 'edge_index' point to valid indices in the interval [0, 1799] (got interval [21, 3776])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/oscar/data/larschan/gcn_gps/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py:266\u001b[0m, in \u001b[0;36mMessagePassing._lift\u001b[0;34m(self, src, edge_index, dim)\u001b[0m\n\u001b[1;32m    265\u001b[0m     index \u001b[38;5;241m=\u001b[39m edge_index[dim]\n\u001b[0;32m--> 266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_select\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIndexError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m21\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     loss, train_acc \u001b[38;5;241m=\u001b[39m train(data)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#     test_acc = test(test_loader)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_acc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Test Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_acc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[20], line 28\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(train_loader)\u001b[0m\n\u001b[1;32m     26\u001b[0m data\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mreshape(data\u001b[38;5;241m.\u001b[39mx, (data\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# data.x = data.x.view(-1, 1).to(torch.float32)\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m#target = torch.reshape(data.y, (100,2)) # CHANGE DIMENSIONS AS YOU CHANGE BATCH SIZE\u001b[39;00m\n\u001b[1;32m     30\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(out, data\u001b[38;5;241m.\u001b[39my)\n",
      "File \u001b[0;32m/oscar/data/larschan/gcn_gps/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/oscar/data/larschan/gcn_gps/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[19], line 18\u001b[0m, in \u001b[0;36mGCN.forward\u001b[0;34m(self, x, edge_index, batch)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_index, batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(edge_index)\n\u001b[0;32m---> 18\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mleaky_relu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     19\u001b[0m    \u001b[38;5;66;03m# x = F.leaky_relu(self.conv2(x, edge_index))\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mleaky_relu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3(x, edge_index))\n",
      "File \u001b[0;32m/oscar/data/larschan/gcn_gps/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/oscar/data/larschan/gcn_gps/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/oscar/data/larschan/gcn_gps/lib/python3.8/site-packages/torch_geometric/nn/conv/sage_conv.py:130\u001b[0m, in \u001b[0;36mSAGEConv.forward\u001b[0;34m(self, x, edge_index, size)\u001b[0m\n\u001b[1;32m    127\u001b[0m     x \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin(x[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mrelu(), x[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    129\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: OptPairTensor)\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin_l(out)\n\u001b[1;32m    133\u001b[0m x_r \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m/oscar/data/larschan/gcn_gps/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py:455\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m decomp_args:\n\u001b[1;32m    453\u001b[0m         kwargs[arg] \u001b[38;5;241m=\u001b[39m decomp_kwargs[arg][i]\n\u001b[0;32m--> 455\u001b[0m coll_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_collect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_user_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    458\u001b[0m msg_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minspector\u001b[38;5;241m.\u001b[39mdistribute(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m, coll_dict)\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_message_forward_pre_hooks\u001b[38;5;241m.\u001b[39mvalues():\n",
      "File \u001b[0;32m/oscar/data/larschan/gcn_gps/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py:329\u001b[0m, in \u001b[0;36mMessagePassing._collect\u001b[0;34m(self, args, edge_index, size, kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Tensor):\n\u001b[1;32m    328\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_size(size, dim, data)\n\u001b[0;32m--> 329\u001b[0m             data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lift\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    331\u001b[0m         out[arg] \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torch_sparse_tensor(edge_index):\n",
      "File \u001b[0;32m/oscar/data/larschan/gcn_gps/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py:269\u001b[0m, in \u001b[0;36mMessagePassing._lift\u001b[0;34m(self, src, edge_index, dim)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIndexError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m index\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim):\n\u001b[0;32m--> 269\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\n\u001b[1;32m    270\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered an index error. Please ensure that all \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    271\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindices in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_index\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m point to valid indices in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    272\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe interval [0, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msrc\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    273\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(got interval \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    274\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(index\u001b[38;5;241m.\u001b[39mmin())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(index\u001b[38;5;241m.\u001b[39mmax())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m])\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[0;31mIndexError\u001b[0m: Encountered an index error. Please ensure that all indices in 'edge_index' point to valid indices in the interval [0, 1799] (got interval [21, 3776])"
     ]
    }
   ],
   "source": [
    "for epoch in range(1,21):\n",
    "    loss, train_acc = train(data)\n",
    "#     test_acc = test(test_loader)\n",
    "    print(f'Epoch: {epoch}, Train: {train_acc}, Test Accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "59e5d9c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch_geometric.deprecation.DataLoader at 0x7f358c84a2e0>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98375168",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "module4_gps",
   "language": "python",
   "name": "module4_gps"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
