{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dfffc6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# import matplotlib.pyplot as plt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "import os\n",
    "import scanpy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, DataLoader, Batch\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "from torch_geometric.nn import GATConv, GCNConv, SAGEConv, MessagePassing, Linear\n",
    "import random\n",
    "from scipy.io import mmread\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torcheval.metrics.functional import multiclass_f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "921695c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime, date\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_npz\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m roc_auc_score, f1_score, precision_recall_curve, auc\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import time\n",
    "from datetime import datetime, date\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from scipy.sparse import load_npz\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_recall_curve, auc\n",
    "from scipy.stats import pearsonr\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch_geometric\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "019e3865",
   "metadata": {},
   "outputs": [],
   "source": [
    "hicmatrix  =pd.read_csv(\"../../chrX_1000000_hic.txt\",header = None)\n",
    "# hicmatrix_test = pd.read_csv(\"../../chrX_2000000_hic.txt\",header = None)\n",
    "epigenomic = pd.read_csv(\"../../train_epigemnomic_1000000.csv\",header =  0).iloc[:,1:].to_numpy()\n",
    "label = pd.read_csv(\"../../train_label.csv\",header = 0).iloc[:,1:].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "114adefa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "       ...,\n",
       "       [  0.,   0.,   0., ..., 157., 269.,  24.],\n",
       "       [  0.,   0.,   0., ..., 269., 130., 233.],\n",
       "       [  0.,   0.,   0., ...,  24., 233., 134.]], dtype=float32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hicmatrix_train_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "563a3b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hicmatrix_train  =pd.read_csv(\"../../chrX_1000000_hic.txt\",header = None)\n",
    "# hicmatrix_test = pd.read_csv(\"../../chrX_2000000_hic.txt\",header = None)\n",
    "# epigenomic_test = pd.read_csv(\"../../test_epigemnomic_2000000.csv\",header =  0).iloc[:,1:].to_numpy()\n",
    "# label_test = pd.read_csv(\"../../test_label.csv\",header = 0).iloc[:,1:].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cefd4f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2001, 24)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epigenomic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19d6b641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([1950,   51]))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(label, return_counts=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6b74b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "hicmatrix_np =hicmatrix.to_numpy(dtype=np.float32)\n",
    "# hicmatrix_test_np = hicmatrix_test.to_numpy(dtype= np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b622da2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random_array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m label \u001b[38;5;241m=\u001b[39m random_array\n",
      "\u001b[0;31mNameError\u001b[0m: name 'random_array' is not defined"
     ]
    }
   ],
   "source": [
    "# label = random_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb5d401c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[3, 1], edge_index=[2, 4])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "edge_index = torch.tensor([[0, 1, 1, 2],\n",
    "                           [1, 0, 2, 1]], dtype=torch.long)\n",
    "x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91439005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of edges: 61946\n"
     ]
    }
   ],
   "source": [
    "# From Whitney\n",
    "\n",
    "def create_comp_graph(correlation, min_corr):\n",
    "    '''Get a graph based on highly correlated features (feat) and given correlation (corr).'''\n",
    "    s_l = [] # Gene 1 = Node 1\n",
    "    d_l  = [] # Gene 2 = Node 2\n",
    "    for i in range(0, correlation.shape[0]):\n",
    "        for j in range(0, correlation.shape[1]):# Get edge and correlation\n",
    "            if correlation[i][j] >= min_corr and i != j: # Ensure the features are at least given correlation (and it won't be a self correlated edge i. e. 1 --> 1)\n",
    "                s_l.append(i)\n",
    "                d_l.append(j)\n",
    "            else:\n",
    "                continue\n",
    "    print(f\"Number of edges: {len(s_l)}\") # Prints # of edges so you can make sure it isn't empty/too large\n",
    "    edge_index = np.array([s_l, d_l]) # Convert to array\n",
    "    return edge_index # Return edge index\n",
    "\n",
    "edge_index = create_comp_graph(hicmatrix_np, 10)\n",
    "temp_edge_index = edge_index\n",
    "# edge_index_test = create_comp_graph(hicmatrix_test_np,10)\n",
    "# temp_edge_index_test = edge_index_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ebe41ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  21,   22,   22,  ..., 2000, 2000, 2000],\n",
       "        [  22,   21,   23,  ..., 1997, 1998, 1999]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "240a01bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  21,   22,   22, ..., 2000, 2000, 2000],\n",
       "       [  22,   21,   23, ..., 1997, 1998, 1999]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0cc2121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 12) -> None:\n",
    "    '''This function allows us to set the seed for the notebook.'''\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    print(f\"Random seed set as {seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00c4dbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1\n",
    "# training_exp_shuffled = training_exp_shuffled + epsilon\n",
    "# training_exp_shuffled = np.log2(training_exp_shuffled)\n",
    "# testing_exp_shuffled = testing_exp_shuffled + epsilon\n",
    "# testing_exp_shuffled = np.log2(testing_exp_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82b307e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_81557/2785758134.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  edge_index = torch.tensor(edge_index, dtype = torch.int64)\n"
     ]
    }
   ],
   "source": [
    "# edge_index_train = torch.tensor(edge_index_train, dtype=torch.int64)\n",
    "# edge_index_test = torch.tensor(edge_index_test,dtype = torch.int64)\n",
    "# train_data = []\n",
    "# test_data = []\n",
    "edge_index = torch.tensor(edge_index, dtype = torch.int64)\n",
    "data = []\n",
    "# Function to convert graph data to PyTorch Geometric Data object\n",
    "def create_data_object(x, y, edge_index):\n",
    "    x = torch.tensor(x, dtype=torch.float32)\n",
    "    y = torch.tensor(y, dtype=torch.long)\n",
    "    return Data(x=x, y=y, edge_index=edge_index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a01ef16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/oscar/data/larschan/gcn_gps/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "data = DataLoader(data, batch_size = 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8f7fb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "05168c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import load_npz\n",
    "import torch\n",
    "import torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0f24f825",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Define model inputs\n",
    "hic_sparse_mat_file = sparse.csr_matrix(hicmatrix_np)\n",
    "mat = (hic_sparse_mat_file)\n",
    "# allNodes_hms = np.load(np_hmods_norm_all_file)\n",
    "hms = epigenomic #only includes features, not node ids\n",
    "X = torch.tensor(hms).float() \n",
    "allNodes = np.arange(2001).astype(int)\n",
    "# geneNodes_labs = np.load(np_nodes_lab_genes_file)\n",
    "\n",
    "# geneNodes = geneNodes_labs[:, -2].astype(int)\n",
    "allLabs = label\n",
    "\n",
    "targetNode_mask = torch.tensor(allNodes).long()\n",
    "\n",
    "\n",
    "# geneLabs = geneNodes_labs[:, -1].astype(float)\n",
    "# allLabs[geneNodes] = geneLabs\n",
    "Y = torch.tensor(allLabs).long()\n",
    "\n",
    "extract = torch_geometric.utils.from_scipy_sparse_matrix(mat)\n",
    "data = torch_geometric.data.Data(edge_index = extract[0], edge_attr = extract[1], x = X, y = Y)\n",
    "G = data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4ecc6032",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Define convolutional and linear layer input/output sizes\n",
    "graph_conv_layer_sizes = [24] + \\\n",
    "    [int(max(256, 256)) \\\n",
    "          for i in np.arange(1, 2, 1)] + [256]\n",
    "        \n",
    "lin_hidden_sizes = [graph_conv_layer_sizes[-1]] + \\\n",
    "    [int(max(256, 2)) \\\n",
    "          for i in np.arange(1, 3, 1)] + [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5c4bfe42",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Randomize node order and split into 70%/15%/15% training/validation/test sets\n",
    "pred_idx_shuff = torch.randperm(targetNode_mask.shape[0])\n",
    "\n",
    "fin_train = np.floor(0.7*pred_idx_shuff.shape[0]).astype(int)\n",
    "fin_valid = np.floor(0.85*pred_idx_shuff.shape[0]).astype(int)\n",
    "train_idx = pred_idx_shuff[:fin_train]\n",
    "valid_idx = pred_idx_shuff[fin_train:fin_valid]\n",
    "test_idx = pred_idx_shuff[fin_valid:]\n",
    "\n",
    "train_gene_ID = targetNode_mask[train_idx].numpy()\n",
    "valid_gene_ID = targetNode_mask[valid_idx].numpy()\n",
    "test_gene_ID = targetNode_mask[test_idx].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7d74cc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN_classification(nn.Module):\n",
    "\n",
    "    def __init__(self, num_feat, num_graph_conv_layers, graph_conv_layer_sizes, num_lin_layers, lin_hidden_sizes, num_classes):\n",
    "        '''\n",
    "        Defines classification model class\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        num_feat [int]: Feature dimension (int)\n",
    "        num_graph_conv_layers [int]: Number of graph convolutional layers (1, 2, or 3)\n",
    "        graph_conv_layer_sizes [int]: Embedding size of graph convolutional layers \n",
    "        num_lin_layers [int]: Number of linear layers (1, 2, or 3)\n",
    "        lin_hidden_sizes [int]: Embedding size of hidden linear layers\n",
    "        num_classes [int]: Number of classes to be predicted(=2)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None.\n",
    "\n",
    "        '''\n",
    "        \n",
    "        super(GCN_classification, self).__init__()\n",
    "\n",
    "        self.num_graph_conv_layers = num_graph_conv_layers\n",
    "        self.num_lin_layers = num_lin_layers\n",
    "        self.dropout_value = 0.5\n",
    "\n",
    "        if self.num_graph_conv_layers == 1:\n",
    "            self.conv1 = SAGEConvCat(graph_conv_layer_sizes[0], graph_conv_layer_sizes[1])\n",
    "        elif self.num_graph_conv_layers == 2:\n",
    "            self.conv1 = SAGEConvCat(graph_conv_layer_sizes[0], graph_conv_layer_sizes[1])\n",
    "            self.conv2 = SAGEConvCat(graph_conv_layer_sizes[1], graph_conv_layer_sizes[2])\n",
    "        elif self.num_graph_conv_layers == 3:\n",
    "            self.conv1 = SAGEConvCat(graph_conv_layer_sizes[0], graph_conv_layer_sizes[1])\n",
    "            self.conv2 = SAGEConvCat(graph_conv_layer_sizes[1], graph_conv_layer_sizes[2])\n",
    "            self.conv3 = SAGEConvCat(graph_conv_layer_sizes[2], graph_conv_layer_sizes[3])\n",
    "        \n",
    "        if self.num_lin_layers == 1:\n",
    "            self.lin1 = nn.Linear(lin_hidden_sizes[0], lin_hidden_sizes[1])\n",
    "        elif self.num_lin_layers == 2:\n",
    "            self.lin1 = nn.Linear(lin_hidden_sizes[0], lin_hidden_sizes[1])\n",
    "            self.lin2 = nn.Linear(lin_hidden_sizes[1], lin_hidden_sizes[2])\n",
    "        elif self.num_lin_layers == 3:\n",
    "            self.lin1 = nn.Linear(lin_hidden_sizes[0], lin_hidden_sizes[1])\n",
    "            self.lin2 = nn.Linear(lin_hidden_sizes[1], lin_hidden_sizes[2])\n",
    "            self.lin3 = nn.Linear(lin_hidden_sizes[2], lin_hidden_sizes[3])\n",
    "            \n",
    "        self.loss_calc = nn.CrossEntropyLoss()\n",
    "        self.torch_softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x, edge_index, train_status=False):\n",
    "        '''\n",
    "        Forward function.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x [tensor]: Node features\n",
    "        edge_index [tensor]: Subgraph mask\n",
    "        train_status [bool]: optional, set to True for dropout\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        scores [tensor]: Pre-normalized class scores\n",
    "\n",
    "        '''\n",
    "\n",
    "        ### Graph convolution module\n",
    "        if self.num_graph_conv_layers == 1:\n",
    "            h = self.conv1(x, edge_index)\n",
    "            h = torch.relu(h)\n",
    "        elif self.num_graph_conv_layers == 2:\n",
    "            h = self.conv1(x, edge_index)\n",
    "            h = torch.relu(h)\n",
    "            h = self.conv2(h, edge_index)\n",
    "            h = torch.relu(h)\n",
    "        elif self.num_graph_conv_layers == 3:\n",
    "            h = self.conv1(x, edge_index)\n",
    "            h = torch.relu(h)\n",
    "            h = self.conv2(h, edge_index)\n",
    "            h = torch.relu(h)\n",
    "            h = self.conv3(h, edge_index)\n",
    "            h = torch.relu(h)\n",
    "            \n",
    "        h = F.dropout(h, p = self.dropout_value, training=train_status)\n",
    "\n",
    "        ### Linear module\n",
    "        if self.num_lin_layers == 1:\n",
    "            scores = self.lin1(h)\n",
    "        elif self.num_lin_layers == 2:\n",
    "            scores = self.lin1(h)\n",
    "            scores = torch.relu(scores)\n",
    "            scores = self.lin2(scores)\n",
    "        elif self.num_lin_layers == 3:\n",
    "            scores = self.lin1(h)\n",
    "            scores = torch.relu(scores)\n",
    "            scores = self.lin2(scores)\n",
    "            scores = torch.relu(scores)\n",
    "            scores = self.lin3(scores)\n",
    "        \n",
    "        return scores\n",
    "    \n",
    "    \n",
    "    def loss(self, scores, labels):\n",
    "        '''\n",
    "        Calculates cross-entropy loss\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        scores [tensor]: Pre-normalized class scores from forward function\n",
    "        labels [tensor]: Class labels for nodes\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        xent_loss [tensor]: Cross-entropy loss\n",
    "\n",
    "        '''\n",
    "\n",
    "        xent_loss = self.loss_calc(scores, labels)\n",
    "\n",
    "        return xent_loss\n",
    "    \n",
    "    \n",
    "    def calc_softmax_pred(self, scores):\n",
    "        '''\n",
    "        Calculates softmax scores and predicted classes\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        scores [tensor]: Pre-normalized class scores\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        softmax [tensor]: Probability for each class\n",
    "        predicted [tensor]: Predicted class\n",
    "\n",
    "        '''\n",
    "        \n",
    "        softmax = self.torch_softmax(scores)\n",
    "        \n",
    "        predicted = torch.argmax(softmax, 1)\n",
    "        \n",
    "        return softmax, predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c576108c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_sparse import SparseTensor, matmul\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527c9989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Union, Tuple\n",
    "from torch_geometric.typing import OptPairTensor, Adj, Size\n",
    "\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn.conv import MessagePassing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a9303719",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SparseTensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSAGEConvCat\u001b[39;00m(MessagePassing):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m    *Note: Source function taken from PyTorch Geometric and modified such that\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m    embeddings are first concatenated and then reduced to out_channel size as\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03m    }\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, in_channels: Union[\u001b[38;5;28mint\u001b[39m, Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m]],\n\u001b[1;32m     36\u001b[0m                  out_channels: \u001b[38;5;28mint\u001b[39m, normalize: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     37\u001b[0m                  bias: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):  \u001b[38;5;66;03m# yapf: disable\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[61], line 71\u001b[0m, in \u001b[0;36mSAGEConvCat\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmessage\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_j: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x_j\n\u001b[0;32m---> 71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmessage_and_aggregate\u001b[39m(\u001b[38;5;28mself\u001b[39m, adj_t: \u001b[43mSparseTensor\u001b[49m,\n\u001b[1;32m     72\u001b[0m                           x: OptPairTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m     73\u001b[0m     adj_t \u001b[38;5;241m=\u001b[39m adj_t\u001b[38;5;241m.\u001b[39mset_value(\u001b[38;5;28;01mNone\u001b[39;00m, layout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m matmul(adj_t, x[\u001b[38;5;241m0\u001b[39m], reduce\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maggr)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SparseTensor' is not defined"
     ]
    }
   ],
   "source": [
    "class SAGEConvCat(MessagePassing):\n",
    "    \"\"\"\n",
    "    *Note: Source function taken from PyTorch Geometric and modified such that\n",
    "    embeddings are first concatenated and then reduced to out_channel size as\n",
    "    per the original GraphSAGE paper.\n",
    "    \n",
    "    The GraphSAGE operator from the `\"Inductive Representation Learning on\n",
    "    Large Graphs\" <https://arxiv.org/abs/1706.02216>`_ paper\n",
    "    .. math::\n",
    "        \\mathbf{x}^{\\prime}_i = \\mathbf{W}_1 \\mathbf{x}_i + \\mathbf{W_2} \\cdot\n",
    "        \\mathrm{mean}_{j \\in \\mathcal{N(i)}} \\mathbf{x}_j\n",
    "    Args:\n",
    "        in_channels (int or tuple): Size of each input sample. A tuple\n",
    "            corresponds to the sizes of source and target dimensionalities.\n",
    "        out_channels (int): Size of each output sample.\n",
    "        normalize (bool, optional): If set to :obj:`True`, output features\n",
    "            will be :math:`\\ell_2`-normalized, *i.e.*,\n",
    "            :math:`\\frac{\\mathbf{x}^{\\prime}_i}\n",
    "            {\\| \\mathbf{x}^{\\prime}_i \\|_2}`.\n",
    "            (default: :obj:`False`)\n",
    "        bias (bool, optional): If set to :obj:`False`, the layer will not learn\n",
    "            an additive bias. (default: :obj:`True`)\n",
    "        **kwargs (optional): Additional arguments of\n",
    "            :class:`torch_geometric.nn.conv.MessagePassing`.\n",
    "\n",
    "    PyTorch Geometric citation:\n",
    "    @inproceedings{Fey/Lenssen/2019,\n",
    "      title={Fast Graph Representation Learning with {PyTorch Geometric}},\n",
    "      author={Fey, Matthias and Lenssen, Jan E.},\n",
    "      booktitle={ICLR Workshop on Representation Learning on Graphs and Manifolds},\n",
    "      year={2019},\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels: Union[int, Tuple[int, int]],\n",
    "                 out_channels: int, normalize: bool = False,\n",
    "                 bias: bool = True, **kwargs):  # yapf: disable\n",
    "        super(SAGEConvCat, self).__init__(aggr='mean', **kwargs)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.normalize = normalize\n",
    "\n",
    "        if isinstance(in_channels, int):\n",
    "            in_channels = (in_channels, in_channels)\n",
    "\n",
    "        self.lin_l = Linear(in_channels[0]*2, out_channels, bias=bias)\n",
    "        \n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.lin_l.reset_parameters()\n",
    "\n",
    "    def forward(self, x: Union[Tensor, OptPairTensor], edge_index: Adj,\n",
    "                size: Size = None) -> Tensor:\n",
    "        \n",
    "        out = self.propagate(edge_index, x=x, size=size)\n",
    "\n",
    "        ### Concatenation\n",
    "        out = torch.cat([x, out], dim=-1)\n",
    "        out = self.lin_l(out)\n",
    "\n",
    "        if self.normalize:\n",
    "            out = F.normalize(out, p=2., dim=-1)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def message(self, x_j: Tensor) -> Tensor:\n",
    "        return x_j\n",
    "\n",
    "    def message_and_aggregate(self, adj_t: SparseTensor,\n",
    "                              x: OptPairTensor) -> Tensor:\n",
    "        adj_t = adj_t.set_value(None, layout=None)\n",
    "        return matmul(adj_t, x[0], reduce=self.aggr)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}({}, {})'.format(self.__class__.__name__, self.in_channels,\n",
    "                                   self.out_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "54d0f5b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SAGEConvCat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m GCN_classification(\u001b[38;5;241m24\u001b[39m, \u001b[38;5;241m3\u001b[39m, graph_conv_layer_sizes, \u001b[38;5;241m3\u001b[39m, lin_hidden_sizes, \u001b[38;5;241m2\u001b[39m)\n",
      "Cell \u001b[0;32mIn[51], line 34\u001b[0m, in \u001b[0;36mGCN_classification.__init__\u001b[0;34m(self, num_feat, num_graph_conv_layers, graph_conv_layer_sizes, num_lin_layers, lin_hidden_sizes, num_classes)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2 \u001b[38;5;241m=\u001b[39m SAGEConvCat(graph_conv_layer_sizes[\u001b[38;5;241m1\u001b[39m], graph_conv_layer_sizes[\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_graph_conv_layers \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m---> 34\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1 \u001b[38;5;241m=\u001b[39m \u001b[43mSAGEConvCat\u001b[49m(graph_conv_layer_sizes[\u001b[38;5;241m0\u001b[39m], graph_conv_layer_sizes[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2 \u001b[38;5;241m=\u001b[39m SAGEConvCat(graph_conv_layer_sizes[\u001b[38;5;241m1\u001b[39m], graph_conv_layer_sizes[\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3 \u001b[38;5;241m=\u001b[39m SAGEConvCat(graph_conv_layer_sizes[\u001b[38;5;241m2\u001b[39m], graph_conv_layer_sizes[\u001b[38;5;241m3\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SAGEConvCat' is not defined"
     ]
    }
   ],
   "source": [
    "model = GCN_classification(24, 3, graph_conv_layer_sizes, 3, lin_hidden_sizes, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8cd914d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/oscar/data/larschan/gcn_gps/lib/python3.8/site-packages/torch_geometric/graphgym/config.py:19: UserWarning: Could not define global config object. Please install 'yacs' via 'pip install yacs' in order to use GraphGym\n",
      "  warnings.warn(\"Could not define global config object. Please install \"\n",
      "/oscar/data/larschan/gcn_gps/lib/python3.8/site-packages/torch_geometric/graphgym/imports.py:14: UserWarning: Please install 'pytorch_lightning' via  'pip install pytorch_lightning' in order to use GraphGym\n",
      "  warnings.warn(\"Please install 'pytorch_lightning' via  \"\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import global_mean_pool, global_max_pool\n",
    "from torch_geometric.graphgym import init_weights\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim1, num_labels):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = SAGEConv(1, hidden_dim1)\n",
    "        self.init_weights(self.conv1)\n",
    "        # self.conv2 = SAGEConv(hidden_dim1, hidden_dim2)\n",
    "        # self.init_weights(self.conv2)\n",
    "        self.conv3 = SAGEConv(hidden_dim1, num_labels)\n",
    "        self.init_weights(self.conv3)\n",
    "        # self.conv4 = SAGEConv(hidden_dim3, num_labels)\n",
    "        # self.init_weights(self.conv4)\n",
    "        self.lin = Linear(num_labels, num_labels)\n",
    "    def forward(self, x, edge_index, batch=None):\n",
    "        print(edge_index)\n",
    "        x = F.leaky_relu(self.conv1(x, edge_index))\n",
    "       # x = F.leaky_relu(self.conv2(x, edge_index))\n",
    "        x = F.leaky_relu(self.conv3(x, edge_index))\n",
    "        # x = F.leaky_relu(self.conv4(x, edge_index))\n",
    "        x = global_mean_pool(x, batch) \n",
    "        x = self.lin(x)\n",
    "        x = F.log_softmax(x, dim=edge_index)\n",
    "        return x\n",
    "\n",
    "    def init_weights(self, layer):\n",
    "        if hasattr(layer, 'weight') and layer.weight is not None:\n",
    "            xavier_uniform_(layer.weight.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad77111f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): SAGEConv(1, 64, aggr=mean)\n",
      "  (conv3): SAGEConv(64, 4, aggr=mean)\n",
      "  (lin): Linear(4, 4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "import tqdm\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_labels=4\n",
    "\n",
    "model = GCN(64, num_labels).to(device)\n",
    "print(model)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion =  nn.CrossEntropyLoss() # change loss for binary classification vs multiclass\n",
    "\n",
    "def accuracy(predictions, targets):\n",
    "    # Assuming predictions and targets are tensors\n",
    "    _, predicted_classes = predictions.max(dim=1)\n",
    "    correct = (predicted_classes == targets).sum().item()\n",
    "    accuracy = correct / targets.size(0)\n",
    "    return accuracy\n",
    "\n",
    "def train(train_loader):\n",
    "    model.train()\n",
    "    avgLoss = 0\n",
    "    avgAcc = 0\n",
    "    for data in tqdm.tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        data.x = torch.reshape(data.x, (data.x.shape[0], 1)).to(torch.float32).to(device)\n",
    "        # data.x = data.x.view(-1, 1).to(torch.float32)\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        #target = torch.reshape(data.y, (100,2)) # CHANGE DIMENSIONS AS YOU CHANGE BATCH SIZE\n",
    "        loss = criterion(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        avgLoss += loss\n",
    "        avgAcc += accuracy(out, data.y)\n",
    "    return (avgLoss / len(train_loader)), (avgAcc / len(train_loader))\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in loader: \n",
    "            # data.x = data.x.view(-1, 1).to(torch.float32)\n",
    "        data.x = torch.reshape(data.x, (data.x.shape[0], 1)).to(torch.float32).to(device)\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        #target = torch.reshape(data.y, (100,2))\n",
    "        pred = torch.argmax(out, dim=1)\n",
    "        correct += int((pred == data.y).sum())\n",
    "    return correct / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9204ae51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/27 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  21,   22,   22,  ..., 3776, 3776, 3776],\n",
      "        [  22,   21,   23,  ..., 3773, 3774, 3775]])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Encountered an index error. Please ensure that all indices in 'edge_index' point to valid indices in the interval [0, 1799] (got interval [21, 3776])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/oscar/data/larschan/gcn_gps/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py:266\u001b[0m, in \u001b[0;36mMessagePassing._lift\u001b[0;34m(self, src, edge_index, dim)\u001b[0m\n\u001b[1;32m    265\u001b[0m     index \u001b[38;5;241m=\u001b[39m edge_index[dim]\n\u001b[0;32m--> 266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_select\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIndexError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m21\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     loss, train_acc \u001b[38;5;241m=\u001b[39m train(data)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#     test_acc = test(test_loader)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_acc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Test Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_acc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[20], line 28\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(train_loader)\u001b[0m\n\u001b[1;32m     26\u001b[0m data\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mreshape(data\u001b[38;5;241m.\u001b[39mx, (data\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# data.x = data.x.view(-1, 1).to(torch.float32)\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m#target = torch.reshape(data.y, (100,2)) # CHANGE DIMENSIONS AS YOU CHANGE BATCH SIZE\u001b[39;00m\n\u001b[1;32m     30\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(out, data\u001b[38;5;241m.\u001b[39my)\n",
      "File \u001b[0;32m/oscar/data/larschan/gcn_gps/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/oscar/data/larschan/gcn_gps/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[19], line 18\u001b[0m, in \u001b[0;36mGCN.forward\u001b[0;34m(self, x, edge_index, batch)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_index, batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(edge_index)\n\u001b[0;32m---> 18\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mleaky_relu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     19\u001b[0m    \u001b[38;5;66;03m# x = F.leaky_relu(self.conv2(x, edge_index))\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mleaky_relu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3(x, edge_index))\n",
      "File \u001b[0;32m/oscar/data/larschan/gcn_gps/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/oscar/data/larschan/gcn_gps/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/oscar/data/larschan/gcn_gps/lib/python3.8/site-packages/torch_geometric/nn/conv/sage_conv.py:130\u001b[0m, in \u001b[0;36mSAGEConv.forward\u001b[0;34m(self, x, edge_index, size)\u001b[0m\n\u001b[1;32m    127\u001b[0m     x \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin(x[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mrelu(), x[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    129\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: OptPairTensor)\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin_l(out)\n\u001b[1;32m    133\u001b[0m x_r \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m/oscar/data/larschan/gcn_gps/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py:455\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m decomp_args:\n\u001b[1;32m    453\u001b[0m         kwargs[arg] \u001b[38;5;241m=\u001b[39m decomp_kwargs[arg][i]\n\u001b[0;32m--> 455\u001b[0m coll_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_collect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_user_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    458\u001b[0m msg_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minspector\u001b[38;5;241m.\u001b[39mdistribute(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m, coll_dict)\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_message_forward_pre_hooks\u001b[38;5;241m.\u001b[39mvalues():\n",
      "File \u001b[0;32m/oscar/data/larschan/gcn_gps/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py:329\u001b[0m, in \u001b[0;36mMessagePassing._collect\u001b[0;34m(self, args, edge_index, size, kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Tensor):\n\u001b[1;32m    328\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_size(size, dim, data)\n\u001b[0;32m--> 329\u001b[0m             data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lift\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    331\u001b[0m         out[arg] \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torch_sparse_tensor(edge_index):\n",
      "File \u001b[0;32m/oscar/data/larschan/gcn_gps/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py:269\u001b[0m, in \u001b[0;36mMessagePassing._lift\u001b[0;34m(self, src, edge_index, dim)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIndexError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m index\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim):\n\u001b[0;32m--> 269\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\n\u001b[1;32m    270\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered an index error. Please ensure that all \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    271\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindices in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_index\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m point to valid indices in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    272\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe interval [0, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msrc\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    273\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(got interval \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    274\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(index\u001b[38;5;241m.\u001b[39mmin())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(index\u001b[38;5;241m.\u001b[39mmax())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m])\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[0;31mIndexError\u001b[0m: Encountered an index error. Please ensure that all indices in 'edge_index' point to valid indices in the interval [0, 1799] (got interval [21, 3776])"
     ]
    }
   ],
   "source": [
    "for epoch in range(1,21):\n",
    "    loss, train_acc = train(data)\n",
    "#     test_acc = test(test_loader)\n",
    "    print(f'Epoch: {epoch}, Train: {train_acc}, Test Accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "59e5d9c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch_geometric.deprecation.DataLoader at 0x7f358c84a2e0>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98375168",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "module4_gps",
   "language": "python",
   "name": "module4_gps"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
