{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dfffc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "import os\n",
    "import scanpy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, DataLoader, Batch\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "from torch_geometric.nn import GATConv, GCNConv, SAGEConv, MessagePassing, Linear\n",
    "import random\n",
    "from scipy.io import mmread\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torcheval.metrics.functional import multiclass_f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from collections import Counter\n",
    "from torch_sparse import SparseTensor, matmul\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_recall_curve, auc\n",
    "import scikitplot as skplt\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04520d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.load('../../../shared_data/bind_gps/hic/interaction_matrix.Xchr_500res.npy')\n",
    "dataset = np.nan_to_num(dataset, nan=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "019e3865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hicmatrix  =pd.read_csv(\"../../chrX_4000000_hic_500.txt\",header = None)\n",
    "# hicmatrix_test = pd.read_csv(\"../../chrX_2000000_hic.txt\",header = None)\n",
    "epigenomic = pd.read_csv(\"./44845_epigemnomic.csv\",header =  0).iloc[:,1:].to_numpy()\n",
    "label = pd.read_csv(\"./44845_label.csv\",header = 0).iloc[:,1:].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "323681b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11986a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: nvidia-smi: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b06d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "hicmatrix = dataset\n",
    "hicmatrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefd4f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "epigenomic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f4ddde",
   "metadata": {},
   "outputs": [],
   "source": [
    "44845/(2*1453)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d6b641",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(label, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b74b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "hicmatrix_np =hicmatrix\n",
    "# hicmatrix_test_np = hicmatrix_test.to_numpy(dtype= np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f7fb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05168c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import load_npz\n",
    "import torch\n",
    "import torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527c9989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Union, Tuple\n",
    "from torch_geometric.typing import OptPairTensor, Adj, Size\n",
    "\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn.conv import MessagePassing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb81000",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedCrossEntropyLoss(nn.Module):\n",
    "    def __init__(self, weights=None):\n",
    "        super(WeightedCrossEntropyLoss, self).__init__()\n",
    "        self.weights = weights\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        # Compute standard cross-entropy loss\n",
    "        ce_loss = nn.functional.cross_entropy(inputs, targets, reduction='none', weight=self.weights)\n",
    "        \n",
    "        # Apply class weights if provided\n",
    "        if self.weights is not None:\n",
    "            ce_loss = ce_loss * self.weights[targets]\n",
    "\n",
    "        # Calculate the mean loss\n",
    "        loss = torch.mean(ce_loss)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8be7b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN_classification(nn.Module):\n",
    "\n",
    "    def __init__(self, num_feat, num_graph_conv_layers, graph_conv_layer_sizes, num_lin_layers, lin_hidden_sizes, num_classes):\n",
    "        '''\n",
    "        Defines classification model class\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        num_feat [int]: Feature dimension (int)\n",
    "        num_graph_conv_layers [int]: Number of graph convolutional layers (1, 2, or 3)\n",
    "        graph_conv_layer_sizes [int]: Embedding size of graph convolutional layers \n",
    "        num_lin_layers [int]: Number of linear layers (1, 2, or 3)\n",
    "        lin_hidden_sizes [int]: Embedding size of hidden linear layers\n",
    "        num_classes [int]: Number of classes to be predicted(=2)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None.\n",
    "\n",
    "        '''\n",
    "        \n",
    "        super(GCN_classification, self).__init__()\n",
    "\n",
    "        self.num_graph_conv_layers = num_graph_conv_layers\n",
    "        self.num_lin_layers = num_lin_layers\n",
    "        self.dropout_value = 0.5\n",
    "\n",
    "        if self.num_graph_conv_layers == 1:\n",
    "            self.conv1 = GCNConv(graph_conv_layer_sizes[0], graph_conv_layer_sizes[1])\n",
    "        elif self.num_graph_conv_layers == 2:\n",
    "            self.conv1 = GCNConv(graph_conv_layer_sizes[0], graph_conv_layer_sizes[1])\n",
    "            self.conv2 = GCNConv(graph_conv_layer_sizes[1], graph_conv_layer_sizes[2])\n",
    "        elif self.num_graph_conv_layers == 3:\n",
    "            self.conv1 = GCNConv(graph_conv_layer_sizes[0], graph_conv_layer_sizes[1])\n",
    "            self.conv2 = GCNConv(graph_conv_layer_sizes[1], graph_conv_layer_sizes[2])\n",
    "            self.conv3 = GCNConv(graph_conv_layer_sizes[2], graph_conv_layer_sizes[3])\n",
    "        \n",
    "        if self.num_lin_layers == 1:\n",
    "            self.lin1 = nn.Linear(lin_hidden_sizes[0], lin_hidden_sizes[1])\n",
    "        elif self.num_lin_layers == 2:\n",
    "            self.lin1 = nn.Linear(lin_hidden_sizes[0], lin_hidden_sizes[1])\n",
    "            self.lin2 = nn.Linear(lin_hidden_sizes[1], lin_hidden_sizes[2])\n",
    "        elif self.num_lin_layers == 3:\n",
    "            self.lin1 = nn.Linear(lin_hidden_sizes[0], lin_hidden_sizes[1])\n",
    "            self.lin2 = nn.Linear(lin_hidden_sizes[1], lin_hidden_sizes[2])\n",
    "            self.lin3 = nn.Linear(lin_hidden_sizes[2], lin_hidden_sizes[3])\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        class_weights = torch.tensor([1.0, 4.0]).to(device)\n",
    "\n",
    "        self.loss_calc = WeightedCrossEntropyLoss(class_weights)\n",
    "        self.torch_softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x, edge_index, train_status=False):\n",
    "        '''\n",
    "        Forward function.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x [tensor]: Node features\n",
    "        edge_index [tensor]: Subgraph mask\n",
    "        train_status [bool]: optional, set to True for dropout\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        scores [tensor]: Pre-normalized class scores\n",
    "\n",
    "        '''\n",
    "\n",
    "        ### Graph convolution module\n",
    "        if self.num_graph_conv_layers == 1:\n",
    "            h = self.conv1(x, edge_index)\n",
    "            h = torch.relu(h)\n",
    "        elif self.num_graph_conv_layers == 2:\n",
    "            h = self.conv1(x, edge_index)\n",
    "            h = torch.relu(h)\n",
    "            h = self.conv2(h, edge_index)\n",
    "            h = torch.relu(h)\n",
    "        elif self.num_graph_conv_layers == 3:\n",
    "            h = self.conv1(x, edge_index)\n",
    "            h = torch.relu(h)\n",
    "            h = self.conv2(h, edge_index)\n",
    "            h = torch.relu(h)\n",
    "            h = self.conv3(h, edge_index)\n",
    "            h = torch.relu(h)\n",
    "            \n",
    "        h = F.dropout(h, p = self.dropout_value, training=train_status)\n",
    "\n",
    "        ### Linear module\n",
    "        if self.num_lin_layers == 1:\n",
    "            scores = self.lin1(h)\n",
    "        elif self.num_lin_layers == 2:\n",
    "            scores = self.lin1(h)\n",
    "            scores = torch.relu(scores)\n",
    "            scores = self.lin2(scores)\n",
    "        elif self.num_lin_layers == 3:\n",
    "            scores = self.lin1(h)\n",
    "            scores = torch.relu(scores)\n",
    "            scores = self.lin2(scores)\n",
    "            scores = torch.relu(scores)\n",
    "            scores = self.lin3(scores)\n",
    "        \n",
    "        return scores\n",
    "    \n",
    "    \n",
    "    def loss(self, scores, labels):\n",
    "        '''\n",
    "        Calculates cross-entropy loss\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        scores [tensor]: Pre-normalized class scores from forward function\n",
    "        labels [tensor]: Class labels for nodes\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        xent_loss [tensor]: Cross-entropy loss\n",
    "\n",
    "        '''\n",
    "\n",
    "        xent_loss = self.loss_calc(scores, labels)\n",
    "\n",
    "        return xent_loss\n",
    "    \n",
    "    \n",
    "    def calc_softmax_pred(self, scores):\n",
    "        '''\n",
    "        Calculates softmax scores and predicted classes\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        scores [tensor]: Pre-normalized class scores\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        softmax [tensor]: Probability for each class\n",
    "        predicted [tensor]: Predicted class\n",
    "\n",
    "        '''\n",
    "        \n",
    "        softmax = self.torch_softmax(scores)\n",
    "        \n",
    "        predicted = torch.argmax(softmax, 1)\n",
    "        \n",
    "        return softmax, predicted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9303719",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGEConvCat(MessagePassing):\n",
    "    \"\"\"\n",
    "    *Note: Source function taken from PyTorch Geometric and modified such that\n",
    "    embeddings are first concatenated and then reduced to out_channel size as\n",
    "    per the original GraphSAGE paper.\n",
    "    \n",
    "    The GraphSAGE operator from the `\"Inductive Representation Learning on\n",
    "    Large Graphs\" <https://arxiv.org/abs/1706.02216>`_ paper\n",
    "    .. math::\n",
    "        \\mathbf{x}^{\\prime}_i = \\mathbf{W}_1 \\mathbf{x}_i + \\mathbf{W_2} \\cdot\n",
    "        \\mathrm{mean}_{j \\in \\mathcal{N(i)}} \\mathbf{x}_j\n",
    "    Args:\n",
    "        in_channels (int or tuple): Size of each input sample. A tuple\n",
    "            corresponds to the sizes of source and target dimensionalities.\n",
    "        out_channels (int): Size of each output sample.\n",
    "        normalize (bool, optional): If set to :obj:`True`, output features\n",
    "            will be :math:`\\ell_2`-normalized, *i.e.*,\n",
    "            :math:`\\frac{\\mathbf{x}^{\\prime}_i}\n",
    "            {\\| \\mathbf{x}^{\\prime}_i \\|_2}`.\n",
    "            (default: :obj:`False`)\n",
    "        bias (bool, optional): If set to :obj:`False`, the layer will not learn\n",
    "            an additive bias. (default: :obj:`True`)\n",
    "        **kwargs (optional): Additional arguments of\n",
    "            :class:`torch_geometric.nn.conv.MessagePassing`.\n",
    "\n",
    "    PyTorch Geometric citation:\n",
    "    @inproceedings{Fey/Lenssen/2019,\n",
    "      title={Fast Graph Representation Learning with {PyTorch Geometric}},\n",
    "      author={Fey, Matthias and Lenssen, Jan E.},\n",
    "      booktitle={ICLR Workshop on Representation Learning on Graphs and Manifolds},\n",
    "      year={2019},\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels: Union[int, Tuple[int, int]],\n",
    "                 out_channels: int, normalize: bool = False,\n",
    "                 bias: bool = True, **kwargs):  # yapf: disable\n",
    "        super(SAGEConvCat, self).__init__(aggr='mean', **kwargs)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.normalize = normalize\n",
    "\n",
    "        if isinstance(in_channels, int):\n",
    "            in_channels = (in_channels, in_channels)\n",
    "\n",
    "        self.lin_l = Linear(in_channels[0]*2, out_channels, bias=bias)\n",
    "        \n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.lin_l.reset_parameters()\n",
    "\n",
    "    def forward(self, x: Union[Tensor, OptPairTensor], edge_index: Adj,\n",
    "                size: Size = None) -> Tensor:\n",
    "        \n",
    "        out = self.propagate(edge_index, x=x, size=size)\n",
    "\n",
    "        ### Concatenation\n",
    "        out = torch.cat([x, out], dim=-1)\n",
    "        out = self.lin_l(out)\n",
    "\n",
    "        if self.normalize:\n",
    "            out = F.normalize(out, p=2., dim=-1)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def message(self, x_j: Tensor) -> Tensor:\n",
    "        return x_j\n",
    "\n",
    "    def message_and_aggregate(self, adj_t: SparseTensor,\n",
    "                              x: OptPairTensor) -> Tensor:\n",
    "        adj_t = adj_t.set_value(None, layout=None)\n",
    "        return matmul(adj_t, x[0], reduce=self.aggr)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}({}, {})'.format(self.__class__.__name__, self.in_channels,\n",
    "                                   self.out_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55be1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_cpu_npy(x):\n",
    "    '''\n",
    "    Simple helper function to transfer GPU tensors to CPU numpy matrices\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x [tensor]: PyTorch tensor stored on GPU\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    new_x [array]: Numpy array stored on CPU\n",
    "\n",
    "    '''\n",
    "\n",
    "    new_x = x.cpu().detach().numpy()\n",
    "    \n",
    "    return new_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e5d9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_classification(model, graph, max_epoch, learning_rate, targetNode_mask, train_idx, valid_idx, optimizer):\n",
    "    '''\n",
    "    Trains model for classification task\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model [GCN_classification]: Instantiation of model class\n",
    "    graph [PyG Data class]: PyTorch Geometric Data object representing the graph\n",
    "    max_epoch [int]: Maximum number of training epochs\n",
    "    learning_rate [float]: Learning rate\n",
    "    targetNode_mask [tensor]: Subgraph mask for training nodes\n",
    "    train_idx [array]: Node IDs corresponding to training set\n",
    "    valid_idx [array]: Node IDs corresponding to validation set\n",
    "    optimizer [PyTorch optimizer class]: PyTorch optimization algorithm\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    train_loss_vec [array]: Training loss for each epoch\n",
    "    train_AUROC_vec [array]: Training AUROC score for each epoch\n",
    "    valid_loss_vec [array]: Validation loss for each epoch\n",
    "    valid_AUROC_vec [array]: Validation AUROC score for each epoch\n",
    "\n",
    "    '''\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = model.to(device)\n",
    "    graph = graph.to(device)\n",
    "\n",
    "    optimizer = optimizer\n",
    "    \n",
    "    train_labels = to_cpu_npy(graph.y[targetNode_mask[train_idx]])\n",
    "    valid_labels = to_cpu_npy(graph.y[targetNode_mask[valid_idx]])\n",
    "    \n",
    "    train_loss_list = []\n",
    "    train_AUROC_vec = np.zeros(np.shape(np.arange(max_epoch)))\n",
    "    valid_loss_list = []\n",
    "    valid_AUROC_vec = np.zeros(np.shape(np.arange(max_epoch)))\n",
    "\n",
    "    model.train()\n",
    "    train_status = True\n",
    "    \n",
    "    print('\\n')\n",
    "    for e in list(range(max_epoch)):\n",
    "        \n",
    "        if e%10 == 0:\n",
    "            print(\"Epoch\", str(e), 'out of', str(max_epoch))\n",
    "        \n",
    "        model.train()\n",
    "        train_status = True\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        ### Only trains on nodes with genes due to masking\n",
    "        forward_scores = model(graph.x.float(), graph.edge_index, train_status)[targetNode_mask]\n",
    "        \n",
    "        train_scores = forward_scores[train_idx]\n",
    "\n",
    "        train_loss  = model.loss(train_scores, torch.LongTensor(train_labels).to(device))\n",
    "        print(train_loss)\n",
    "\n",
    "        train_softmax, _ = model.calc_softmax_pred(train_scores)\n",
    "\n",
    "        train_loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "            \n",
    "        ### Calculate training and validation loss, AUROC scores\n",
    "        model.eval()\n",
    "        \n",
    "        valid_scores = forward_scores[valid_idx]\n",
    "        valid_loss  = model.loss(valid_scores, torch.LongTensor(valid_labels).to(device))\n",
    "        valid_softmax, _ = model.calc_softmax_pred(valid_scores) \n",
    "\n",
    "        train_loss_list.append(train_loss.item())\n",
    "        train_softmax = to_cpu_npy(train_softmax)\n",
    "        train_AUROC = roc_auc_score(train_labels, train_softmax[:,1], average=\"micro\")\n",
    "\n",
    "        valid_loss_list.append(valid_loss.item())\n",
    "        valid_softmax = to_cpu_npy(valid_softmax)\n",
    "        valid_AUROC = roc_auc_score(valid_labels, valid_softmax[:,1], average=\"micro\")\n",
    "        \n",
    "        train_AUROC_vec[e] = train_AUROC\n",
    "        valid_AUROC_vec[e] = valid_AUROC\n",
    "\n",
    "    train_loss_vec = np.reshape(np.array(train_loss_list), (-1, 1))\n",
    "    valid_loss_vec = np.reshape(np.array(valid_loss_list), (-1, 1))\n",
    "\n",
    "    return train_loss_vec, train_AUROC_vec, valid_loss_vec, valid_AUROC_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98375168",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model_classification(model, graph, targetNode_mask, train_idx, valid_idx, test_idx):\n",
    "    '''\n",
    "    Runs fully trained classification model and compute evaluation statistics\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model [GCN_classification]: Instantiation of model class\n",
    "    graph [PyG Data class]: PyTorch Geometric Data object representing the graph\n",
    "    targetNode_mask [tensor]: Mask ensuring model only trains on nodes with genes\n",
    "    train_idx [array]: Node IDs corresponding to training set;\n",
    "        analogous for valid_idx and test_idx\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    test_AUROC [float]: Test set AUROC score;\n",
    "        analogous for train_AUROC (training set) and valid_AUPR (validation set)\n",
    "    test_AUPR [float]: Test set AUPR score\n",
    "        analogous for train_AUPR (training set) and valid_AUPR (validation set)\n",
    "    test_pred [array]: Test set predictions;\n",
    "        analogous for train_pred (training set) and valid_pred (validation set)\n",
    "    test_labels [array]: Test set labels;\n",
    "        analagous for train_labels (training set) and valid_labels (validation set)\n",
    "    '''\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = model.to(device)\n",
    "    graph = graph.to(device)\n",
    "    test_labels = to_cpu_npy(graph.y[targetNode_mask[test_idx]])\n",
    "    \n",
    "    model.eval()\n",
    "    train_status=False\n",
    "\n",
    "    forward_scores = model(graph.x.float(), graph.edge_index, train_status)[targetNode_mask]\n",
    "\n",
    "    test_scores = forward_scores[test_idx]\n",
    "    test_softmax, test_pred = model.calc_softmax_pred(test_scores) \n",
    "    \n",
    "    test_softmax = to_cpu_npy(test_softmax)\n",
    "    test_pred = to_cpu_npy(test_pred)\n",
    "    test_AUROC = roc_auc_score(test_labels, test_softmax[:,1], average=\"micro\")\n",
    "    test_precision, test_recall, thresholds = precision_recall_curve(test_labels, test_softmax[:,1])\n",
    "    test_AUPR = auc(test_recall, test_precision)\n",
    "    # test_F1 = f1_score(test_labels, test_pred, average=\"micro\")\n",
    "    \n",
    "    train_scores = forward_scores[train_idx]\n",
    "    train_labels = to_cpu_npy(graph.y[targetNode_mask[train_idx]])\n",
    "    train_softmax, train_pred = model.calc_softmax_pred(train_scores) \n",
    "    train_pred = to_cpu_npy(train_pred)\n",
    "    train_softmax = to_cpu_npy(train_softmax)\n",
    "    train_precision, train_recall, thresholds = precision_recall_curve(train_labels, train_softmax[:,1])\n",
    "    train_AUPR = auc(train_recall, train_precision)\n",
    "    # train_F1 = f1_score(train_labels, train_pred, average=\"micro\")\n",
    "\n",
    "    valid_scores = forward_scores[valid_idx]\n",
    "    valid_labels = to_cpu_npy(graph.y[targetNode_mask[valid_idx]])\n",
    "    valid_softmax, valid_pred = model.calc_softmax_pred(valid_scores) \n",
    "    valid_pred = to_cpu_npy(valid_pred)\n",
    "    valid_softmax = to_cpu_npy(valid_softmax)\n",
    "    valid_precision, valid_recall, thresholds = precision_recall_curve(valid_labels, valid_softmax[:,1])\n",
    "    valid_AUPR = auc(valid_recall, valid_precision)\n",
    "    # valid_F1 = f1_score(valid_labels, valid_pred, average=\"micro\")\n",
    "\n",
    "    return test_AUROC, test_AUPR, test_pred, test_labels,test_softmax, train_AUPR, train_pred, train_labels, \\\n",
    "        valid_AUPR, valid_pred, valid_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9a2c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Define model inputs\n",
    "hic_sparse_mat_file = sparse.csr_matrix(hicmatrix_np)\n",
    "mat = (hic_sparse_mat_file)\n",
    "# allNodes_hms = np.load(np_hmods_norm_all_file)\n",
    "hms = epigenomic #only includes features, not node ids\n",
    "X = torch.tensor(hms).float().reshape(-1,24)\n",
    "allNodes = np.arange(44845).astype(int)\n",
    "\n",
    "\n",
    "allLabs = label\n",
    "\n",
    "targetNode_mask = torch.tensor(allNodes).long()\n",
    "\n",
    "\n",
    "\n",
    "Y = torch.tensor(allLabs).long().reshape(-1)\n",
    "\n",
    "extract = torch_geometric.utils.from_scipy_sparse_matrix(mat)\n",
    "data = torch_geometric.data.Data(edge_index = extract[0], edge_attr = extract[1], x = X, y = Y)\n",
    "G = data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e360411c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def count_occurrences(arr):\n",
    "    unique_elements, counts = np.unique(arr, return_counts=True)\n",
    "    result = dict(zip(unique_elements, counts))\n",
    "    return result\n",
    "\n",
    "# Example usage:\n",
    "# my_array = np.array([1, 2, 3, 1, 2, 3, 4, 5, 1, 1, 2])\n",
    "# result = count_occurrences(valid_labels)\n",
    "# print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5c124e",
   "metadata": {},
   "outputs": [],
   "source": [
    "allLabs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61189ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_occurrences(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3d8c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_flag = 0\n",
    "max_epoch = 100\n",
    "learning_rate = 1e-4\n",
    "num_graph_conv_layers = 2\n",
    "graph_conv_embed_size = 256\n",
    "num_lin_layers = 3\n",
    "lin_hidden_size = 256\n",
    "random_seed = 0\n",
    "num_feat = 24\n",
    "num_classes = 2\n",
    "task = 'Classification'\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f42393",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Define convolutional and linear layer input/output sizes\n",
    "# graph_conv_layer_sizes = [num_feat] + \\\n",
    "#     [int(max(graph_conv_embed_size, lin_hidden_size)) \\\n",
    "#           for i in np.arange(1, num_graph_conv_layers, 1)] + [lin_hidden_size]\n",
    "# print(graph_conv_layer_sizes)        \n",
    "# lin_hidden_sizes = [graph_conv_layer_sizes[-1]] + \\\n",
    "#     [int(max(lin_hidden_size, num_classes)) \\\n",
    "#           for i in np.arange(1, num_lin_layers, 1)] + [num_classes]\n",
    "# print(lin_hidden_sizes)\n",
    "graph_conv_layer_sizes = [24,256,256]\n",
    "lin_hidden_sizes = [256,128,128,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97359851",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###Randomize node order and split into 70%/15%/15% training/validation/test sets\n",
    "pred_idx_shuff = torch.randperm(targetNode_mask.shape[0])\n",
    "\n",
    "fin_train = np.floor(0.5*pred_idx_shuff.shape[0]).astype(int)\n",
    "fin_valid = np.floor(0.75*pred_idx_shuff.shape[0]).astype(int)\n",
    "train_idx = pred_idx_shuff[:fin_train]\n",
    "valid_idx = pred_idx_shuff[fin_train:fin_valid]\n",
    "test_idx = pred_idx_shuff[fin_valid:]\n",
    "\n",
    "train_gene_ID = targetNode_mask[train_idx].numpy()\n",
    "valid_gene_ID = targetNode_mask[valid_idx].numpy()\n",
    "test_gene_ID = targetNode_mask[test_idx].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27db8cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN_classification(num_feat, num_graph_conv_layers, graph_conv_layer_sizes, num_lin_layers, lin_hidden_sizes, num_classes)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0055668d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(filter(lambda p : p.requires_grad, model.parameters()), \n",
    "                            lr = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f95964",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"\\n\"+\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0f5a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ed5ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_vec, train_AUROC_vec, valid_loss_vec, valid_AUROC_vec = \\\n",
    "        train_model_classification(model, G, max_epoch, learning_rate, targetNode_mask, train_idx, valid_idx, optimizer)\n",
    "    \n",
    "    ### Evaluate model\n",
    "test_AUROC, test_AUPR, test_pred, test_labels,test_softmax, train_AUPR, train_pred, train_labels, \\\n",
    "        valid_AUPR, valid_pred, valid_labels = \\\n",
    "            eval_model_classification(model, G, targetNode_mask, train_idx, valid_idx, test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33716c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860b8043",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_occurrences(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3ad068",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_AUPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6feeac25",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_AUPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adc4014",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af75c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e8da4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48f5225",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_AUPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797a5a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_AUROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604a8fe9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958e1a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac09fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24b24f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(count_occurrences(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56e3f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# from sklearn.metrics import plot_roc_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad48e243",
   "metadata": {},
   "outputs": [],
   "source": [
    "testy = test_pred\n",
    "yhat_classes = test_labels\n",
    " \n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(testy, yhat_classes)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(testy, yhat_classes)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(testy, yhat_classes)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(testy, yhat_classes)\n",
    "print('F1 score: %f' % f1)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bbcbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scikitplot as skplt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_true = test_labels\n",
    "y_probas = test_softmax# predicted probabilities generated by sklearn classifier\n",
    "skplt.metrics.plot_roc_curve(y_true, y_probas,curves = 'macro')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd80cad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(test_labels,test_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              )\n",
    "disp.plot()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8c7412",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gc_new",
   "language": "python",
   "name": "gc_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
